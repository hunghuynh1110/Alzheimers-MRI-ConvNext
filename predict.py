
# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IRp9aEbJzVohFPLVq5ECtp0j9LCQNPLh
"""

# --- IMPORTS (Remain at top level) ---
import os
import numpy as np
import torch
import torch.nn as nn
from torch.optim.swa_utils import AveragedModel
from sklearn.metrics import roc_auc_score, classification_report, balanced_accuracy_score


from constants import (
    DEVICE_MPS, DEVICE_CUDA, DEVICE_CPU, EPOCHS,
    DATA_ROOT, BATCH_SIZE, LR, SWA_LR,
    WD, DROP_PATH_RATE,
    NUM_CLASSES
)
# --- LOCAL IMPORTS (Remain at top level) ---
try:
    from modules import ConvNeXtMRI
    from dataset import get_loaders
except ImportError:
    print("‚ùå Error: Make sure 'modules.py' and 'dataset.py' are in the same directory.")
    print("   (Or that they are in the 'recognition/convnext_alzheimer_49384848' directory)")
    exit()
    
DATA_ROOT = "/content/data/AD_NC"


# === 4. Define Model Architecture (Remain at top level) ===
# This MUST match the architecture used for training
def create_model():
    """Helper function to create a new model instance."""
    return ConvNeXtMRI(
        in_chans=3,
        num_classes=NUM_CLASSES,
        depths=[3, 3, 9, 3],
        dims=[96, 192, 384, 768],
        drop_path_rate=DROP_PATH_RATE
    ) # .to(DEVICE) will be handled in the main block

# === 5. Helper Function for Evaluation (Remain at top level) ===
def evaluate_model(model_to_test, test_loader, DEVICE, model_name="Model"):
    """Runs a model through the test_loader and prints metrics."""
    print(f"\n--- Evaluating {model_name} ---")
    model_to_test.eval()

    all_labels = []
    all_preds = []
    all_probs = [] # Probabilities for the positive class (class 1)
    test_correct = 0
    test_total = 0

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)

            outputs = model_to_test(inputs)
            probs = torch.softmax(outputs, dim=1)[:, 1]
            _, predicted = outputs.max(1)

            test_total += labels.size(0)
            test_correct += predicted.eq(labels).sum().item()

            all_probs.extend(probs.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_preds.extend(predicted.cpu().numpy())

    # --- FIX 2: Corrected 'total' to 'test_total' ---
    test_acc = 100 * test_correct / test_total if test_total > 0 else 0
    # ------------------------------------------------

    test_auc = roc_auc_score(all_labels, all_probs)

    print(f"üß† [{model_name}] Test Accuracy: {test_acc:.2f}%")
    print(f"üìà [{model_name}] Test AUC: {test_auc:.4f}")
    print(f"\nClassification Report ({model_name}):")
    print(classification_report(all_labels, all_preds, target_names=['AD (0)', 'NC (1)']))

    try:
        num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"üß© [{model_name}] Model parameters: {num_params/1e6:.2f}M")
    except Exception:
        pass

# === Feature extraction & projection helpers ===
def _find_last_linear(m: nn.Module):
    """Return the last nn.Linear in the model (assumed classifier)."""
    last = None
    for module in m.modules():
        if isinstance(module, nn.Linear):
            last = module
    return last

@torch.no_grad()
def collect_embeddings(model_to_test, data_loader, device):
    """
    Collect one embedding per sample from the penultimate layer.
    If a final Linear is found, capture its *input* via a forward hook;
    otherwise fall back to using logits as features.
    Returns: (embeddings [N,D], labels [N])
    """
    model_to_test.eval()
    last_linear = _find_last_linear(model_to_test)
    captured = []
    handle = None
    if last_linear is not None:
        def _hook(module, inputs, output):
            captured.append(inputs[0].detach().cpu())
        handle = last_linear.register_forward_hook(_hook)

    feats, lbls = [], []
    for x, y in data_loader:
        x = x.to(device)
        y = y.to(device)
        out = model_to_test(x)  # triggers hook if present
        if last_linear is not None:
            feats.append(captured.pop(0))
        else:
            feats.append(out.detach().cpu())
        lbls.append(y.detach().cpu())

    if handle is not None:
        handle.remove()

    feats = torch.cat(feats, dim=0).numpy()
    lbls = torch.cat(lbls, dim=0).numpy()
    return feats, lbls

def project_and_plot(embeddings, labels, out_path,
                     title="UMAP Projection of Test Set Feature Embeddings"):
    """
    Project embeddings to 2D (UMAP; t-SNE fallback) and save a labeled scatter.
    Also saves the raw 2D coordinates and labels as an .npz next to the image.
    """
    method = "UMAP"
    try:
        if _HAS_UMAP:
            reducer = umap.UMAP(n_components=2, random_state=42)
            coords = reducer.fit_transform(embeddings)
        else:
            raise ImportError
    except Exception:
        from sklearn.manifold import TSNE
        reducer = TSNE(n_components=2, random_state=42, init="pca", learning_rate="auto")
        coords = reducer.fit_transform(embeddings)
        method = "t-SNE (fallback)"

    x, y = coords[:, 0], coords[:, 1]
    labels = np.asarray(labels)

    plt.figure(figsize=(10, 7))
    for cls_val, name in [(0, "AD"), (1, "NC")]:
        mask = labels == cls_val
        plt.scatter(x[mask], y[mask], s=12, alpha=0.7, label=name)

    plt.title(title)
    plt.xlabel(f"{method}-1")
    plt.ylabel(f"{method}-2")
    plt.legend(title="Label")
    plt.tight_layout()
    plt.savefig(out_path, dpi=220)
    plt.close()

    # Save raw coordinates & labels for reproducibility
    np.savez(os.path.splitext(out_path)[0] + ".npz",
             coords=coords, labels=labels, method=method)
    print(f"üìä Saved projection plot to: {out_path}")


from constants import DATA_ROOT
# === FIX 1: Wrap all executable code in __name__ == '__main__' ===
if __name__ == '__main__':

    # === 1. Configuration ===
    MODEL_SUBFOLDER = "recognition/convnext_alzheimer_49384848"
    os.makedirs(MODEL_SUBFOLDER, exist_ok=True)
    
    print(f"Data root set to: {DATA_ROOT}")
    if not os.path.exists(DATA_ROOT):
        print(f"‚ö†Ô∏è Warning: Data directory not found at {DATA_ROOT}")
        print("Please update DATA_ROOTs to the correct path.")

    # === 2. Device Setup ===
    if torch.cuda.is_available():
        DEVICE = torch.device("cuda")
        torch.backends.cudnn.benchmark = True
    elif torch.backends.mps.is_available():
        DEVICE = torch.device("mps")
    else:
        DEVICE = torch.device("cpu")
    print(f"Using device: {DEVICE}")

    # === 3. Load Test Data ===
    try:
        _, _, test_loader = get_loaders(
            data_root  =  DATA_ROOT,
            batch_size = BATCH_SIZE
        )
        print(f"Loaded test dataset: {len(test_loader.dataset)} images")
    except Exception as e:
        print(f"‚ùå Error loading data: {e}")
        print("Please ensure 'dataset.py' is present and DATA_ROOTs is correct.")
        exit()

    # === 6. Load and Test 'best_model_test_acc.pth' ===
    model_path = os.path.join('best_model.pth')

    if not os.path.exists(model_path):
        print(f"File not found: {model_path}")

    if os.path.exists(model_path):
        try:
            model = create_model().to(DEVICE) # Move model to device
            model.load_state_dict(torch.load(model_path, map_location=DEVICE))
            print(f"\n‚úÖ Loaded standard weights from: {model_path}")
            
            # Pass test_loader and DEVICE as arguments
            evaluate_model(model, test_loader, DEVICE, f"Best Model ({os.path.basename(model_path)})")
            
                
        except Exception as e:
            print(f"‚ùå Error loading {model_path}: {e}")
            print("Ensure 'modules.py' and model definition match the saved weights.")
    else:
        print(f"‚ö†Ô∏è Could not find {model_path}. Skipping standard model test.")
    
    # === 7. SWA  ===
    swa_model_path = os.path.join( 'swa_model.pth')
    if os.path.exists(swa_model_path):
        try:
            base_model_for_swa = create_model() # Don't move to device yet
            swa_model = AveragedModel(base_model_for_swa).to(DEVICE)
            swa_model.load_state_dict(torch.load(swa_model_path, map_location=DEVICE))
            print(f"\n‚úÖ Loaded SWA weights from: {swa_model_path}")
    
            # Pass test_loader and DEVICE as arguments
            evaluate_model(swa_model, test_loader, DEVICE, "SWA Model")
    
        except Exception as e:
            print(f"‚ùå Error loading {swa_model_path}: {e}")
            print("Ensure 'torch.optim.swa_utils.AveragedModel' is imported.")
    else:
        print(f"‚ö†Ô∏è File not found: {swa_model_path}. Skipping SWA model test.")

    print("\n--- Evaluation Complete ---")

    # (Removed the google.colab lines that would crash here)